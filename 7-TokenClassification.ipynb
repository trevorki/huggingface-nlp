{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd406462-60d8-4f4e-9934-131d78e61bdc",
   "metadata": {
    "id": "dd406462-60d8-4f4e-9934-131d78e61bdc"
   },
   "source": [
    "# Token Classification\n",
    "This includes any problem that can be formulated as \"attributing a label to each token in a sentence,\" eg\n",
    "- Named Entity Recognition (NER)\n",
    "- Part-of-speech tagging (POS)\n",
    "- Chunking: finding the tokens that belong to the same entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ihGI3CT0lZT1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ihGI3CT0lZT1",
    "outputId": "db6bf5f1-5514-4e2d-a2d5-80e486a4780c"
   },
   "outputs": [],
   "source": [
    "# For training in colab\n",
    "\n",
    "# import os\n",
    "# import sys\n",
    "\n",
    "\n",
    "# # Connect to google drive\n",
    "# from google.colab import drive\n",
    "# os.chdir(\"/content\")\n",
    "# drive.mount(\"/content/gdrive\")\n",
    "\n",
    "# # Load colab_utils funtions\n",
    "# sys.path.append(f\"/content/gdrive/MyDrive/repos/colab-utils\")\n",
    "# import colab_utils\n",
    "\n",
    "# colab_utils.load_env_vars()\n",
    "# colab_utils.git_set_config()\n",
    "\n",
    "# PARENT_FOLDER = \"/content/gdrive/MyDrive/repos\"\n",
    "# os.chdir(PARENT_FOLDER)\n",
    "\n",
    "# git_repo = 'trevorki/huggingface-nlp' # replace with actual values\n",
    "# colab_utils.git_clone_repo(git_repo)\n",
    "\n",
    "# REPO_FOLDER = f\"{PARENT_FOLDER}/{git_repo.split('/')[1]}\"\n",
    "# os.chdir(REPO_FOLDER)\n",
    "\n",
    "# # !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b64916-b4f5-40e7-8eb5-436c92454976",
   "metadata": {
    "id": "75b64916-b4f5-40e7-8eb5-436c92454976"
   },
   "source": [
    "## Dataset\n",
    "Use the `CoNLL-2003 dataset`, which contains news stories from Reuters. It contains labels for the three tasks we mentioned earlier: NER, POS, and chunking.\n",
    "\n",
    "A big difference from other datasets is that the input texts are not presented as sentences or documents, but lists of words (the last column is called tokens, but it contains words in the sense that these are pre-tokenized inputs that still need to go through the tokenizer for subword tokenization).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83f0d23d-4beb-473e-987e-b1da7a64d8fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83f0d23d-4beb-473e-987e-b1da7a64d8fc",
    "outputId": "59007c70-26b9-4664-fb0a-f76df49db538"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 14041\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3250\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'tokens', 'pos_tags', 'chunk_tags', 'ner_tags'],\n",
       "        num_rows: 3453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"conll2003\")\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4c62c96-f4a1-441a-85fe-2f119813440d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4c62c96-f4a1-441a-85fe-2f119813440d",
    "outputId": "ce07ea0f-7380-4da2-9866-ebfc1cd4bb22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'lamb', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are not tokens, but lists of words\n",
    "raw_datasets[\"train\"][0][\"tokens\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a02bd8-8338-4e4d-8d7b-494c26e279da",
   "metadata": {
    "id": "56a02bd8-8338-4e4d-8d7b-494c26e279da"
   },
   "source": [
    "### NER labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceac9334-a940-4c9b-9569-e7b3049df1b3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ceac9334-a940-4c9b-9569-e7b3049df1b3",
    "outputId": "1b85701e-d710-4361-eb88-0dd9511d849e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0, 7, 0, 0, 0, 7, 0, 0]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"ner_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b819f6f7-8fdf-4e1f-adc9-b04265b20faa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b819f6f7-8fdf-4e1f-adc9-b04265b20faa",
    "outputId": "ff197339-99f0-4497-fcee-933172e4be89"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\n",
    "label_names = ner_feature.feature.names\n",
    "label_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f845207-5cf3-44fc-be31-47ea6d7fa0d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f845207-5cf3-44fc-be31-47ea6d7fa0d1",
    "outputId": "a520189f-d45d-49a1-bc5c-17faf551400e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU    rejects German call to boycott British lamb . \n",
      "B-ORG O       B-MISC O    O  O       B-MISC  O    O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = label_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47028599-7bc7-4664-a4e8-f0bb2970a9f0",
   "metadata": {
    "id": "47028599-7bc7-4664-a4e8-f0bb2970a9f0"
   },
   "source": [
    "### POS Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d380d3-c84d-4625-ab2e-2a360a4a66f8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "00d380d3-c84d-4625-ab2e-2a360a4a66f8",
    "outputId": "3c9fbaa4-1a73-491b-e60a-fc511286afe7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[22, 42, 16, 21, 35, 37, 16, 21, 7]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"pos_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9af8b9-e62a-48cb-8628-225d19096d4c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9c9af8b9-e62a-48cb-8628-225d19096d4c",
    "outputId": "89c7f67e-b216-4338-f55f-0a4aba959365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\"', \"''\", '#', '$', '(', ')', ',', '.', ':', '``', 'CC', 'CD', 'DT', 'EX', 'FW', 'IN', 'JJ', 'JJR', 'JJS', 'LS', 'MD', 'NN', 'NNP', 'NNPS', 'NNS', 'NN|SYM', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'SYM', 'TO', 'UH', 'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP$', 'WRB']\n"
     ]
    }
   ],
   "source": [
    "pos_feature = raw_datasets[\"train\"].features[\"pos_tags\"]\n",
    "pos_names = pos_feature.feature.names\n",
    "print(pos_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3160c4-bb1e-4990-bd62-6105996e4f69",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db3160c4-bb1e-4990-bd62-6105996e4f69",
    "outputId": "255b7744-03f2-474c-d919-dc8423ef22f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU  rejects German call to boycott British lamb . \n",
      "NNP VBZ     JJ     NN   TO VB      JJ      NN   . \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][0][\"pos_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = pos_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e4f24-0858-475d-9f3d-505c76d2904c",
   "metadata": {
    "id": "592e4f24-0858-475d-9f3d-505c76d2904c"
   },
   "source": [
    "### Chunking labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6ea1c2-1ef8-438c-b918-5062433cc098",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "be6ea1c2-1ef8-438c-b918-5062433cc098",
    "outputId": "bf0ce6da-0bbe-4755-e4fd-3fccc95a8fec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[11, 21, 11, 12, 21, 22, 11, 12, 0]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0][\"chunk_tags\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c6dc68-338c-41bc-b2ef-1ee4f920381d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "10c6dc68-338c-41bc-b2ef-1ee4f920381d",
    "outputId": "a92b1c85-bccc-4ea9-dddb-44529b28176c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-ADJP', 'I-ADJP', 'B-ADVP', 'I-ADVP', 'B-CONJP', 'I-CONJP', 'B-INTJ', 'I-INTJ', 'B-LST', 'I-LST', 'B-NP', 'I-NP', 'B-PP', 'I-PP', 'B-PRT', 'I-PRT', 'B-SBAR', 'I-SBAR', 'B-UCP', 'I-UCP', 'B-VP', 'I-VP']\n"
     ]
    }
   ],
   "source": [
    "chunk_feature = raw_datasets[\"train\"].features[\"chunk_tags\"]\n",
    "chunk_names = chunk_feature.feature.names\n",
    "print(chunk_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b32c3-1dee-4dbc-ab51-0e5466e95e3b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "836b32c3-1dee-4dbc-ab51-0e5466e95e3b",
    "outputId": "99da175f-f2aa-4c97-8964-94682e85751d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EU   rejects German call to   boycott British lamb . \n",
      "B-NP B-VP    B-NP   I-NP B-VP I-VP    B-NP    I-NP O \n"
     ]
    }
   ],
   "source": [
    "words = raw_datasets[\"train\"][0][\"tokens\"]\n",
    "labels = raw_datasets[\"train\"][0][\"chunk_tags\"]\n",
    "line1 = \"\"\n",
    "line2 = \"\"\n",
    "for word, label in zip(words, labels):\n",
    "    full_label = chunk_names[label]\n",
    "    max_length = max(len(word), len(full_label))\n",
    "    line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "    line2 += full_label + \" \" * (max_length - len(full_label) + 1)\n",
    "\n",
    "print(line1)\n",
    "print(line2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244e67af-f95f-4663-8194-a1b47e7f5942",
   "metadata": {
    "id": "244e67af-f95f-4663-8194-a1b47e7f5942"
   },
   "source": [
    "# Tokenize\n",
    "Since the tokenizer splits some words into multiple tokens we have to keed track of the `word_ids` to map them to their words later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09aca07f-c3fb-431c-a396-2e2453b3f6c5",
   "metadata": {
    "id": "09aca07f-c3fb-431c-a396-2e2453b3f6c5"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8902ede9-6e3b-4039-92df-2ab08326a746",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8902ede9-6e3b-4039-92df-2ab08326a746",
    "outputId": "1aeb8e46-d145-4f2c-a07e-22b3c2ec463e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']\n",
      "word_ids: [None, 0, 1, 2, 3, 4, 5, 6, 7, 7, 8, None]\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(raw_datasets[\"train\"][0][\"tokens\"], is_split_into_words=True)\n",
    "print(f\"tokens: {inputs.tokens()}\")\n",
    "print(f\"word_ids: {inputs.word_ids()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7074c6-65e9-4e39-b4d4-3055fa7d74a8",
   "metadata": {
    "id": "ed7074c6-65e9-4e39-b4d4-3055fa7d74a8"
   },
   "source": [
    "Since the labels don't have the special characters or the works split into multiple tokens, we must align the tokenized inputs with the labels.\n",
    "To"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f0b38f2-574e-42c3-b19b-1d56380d5813",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6f0b38f2-574e-42c3-b19b-1d56380d5813",
    "outputId": "15500e58-6738-46b7-96f8-dcb7828bba01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 dataset labels:\n",
      "\t[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "12 tokenized inputs:\n",
      "\t['[CLS]', 'EU', 'rejects', 'German', 'call', 'to', 'boycott', 'British', 'la', '##mb', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(raw_datasets['train'][0]['ner_tags'])} dataset labels:\\n\\t{raw_datasets['train'][0]['ner_tags']}\")\n",
    "print(f\"{len(inputs.tokens())} tokenized inputs:\\n\\t{inputs.tokens()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe2ee1fd-94be-42b4-9a62-99a92cacc792",
   "metadata": {
    "id": "fe2ee1fd-94be-42b4-9a62-99a92cacc792"
   },
   "outputs": [],
   "source": [
    "def align_labels_with_tokens(labels, word_ids):\n",
    "    \"\"\"Adds items to labels to make them match the length of word_ids, by\n",
    "    - duplicating the labels for tokens that were split from the same word\n",
    "    - giving a label of -100 for all special tokens (so that it is ignored by coss entropy loss\n",
    "    RETURNS:\n",
    "        list: the new labels\"\"\"\n",
    "    new_labels = []\n",
    "    current_word = None\n",
    "    for word_id in word_ids:\n",
    "        if word_id != current_word:\n",
    "            # Start of a new word!\n",
    "            current_word = word_id\n",
    "            label = -100 if word_id is None else labels[word_id]\n",
    "            new_labels.append(label)\n",
    "        elif word_id is None:\n",
    "            # Special token\n",
    "            new_labels.append(-100)\n",
    "        else:\n",
    "            # Same word as previous token\n",
    "            label = labels[word_id]\n",
    "            # If the label is B-XXX we change it to I-XXX\n",
    "            if label % 2 == 1:\n",
    "                label += 1 # this changes it from B to I\n",
    "            new_labels.append(label)\n",
    "\n",
    "    return new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d2aab36-08b3-434b-ab78-c2d7c29261b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d2aab36-08b3-434b-ab78-c2d7c29261b6",
    "outputId": "df3833eb-f916-46c9-fe5b-d7b53aee3ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 7, 0, 0, 0, 7, 0, 0]\n",
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n"
     ]
    }
   ],
   "source": [
    "labels = raw_datasets[\"train\"][0][\"ner_tags\"]\n",
    "word_ids = inputs.word_ids()\n",
    "print(labels)\n",
    "print(align_labels_with_tokens(labels, word_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d06cad8-3c32-48a0-9b98-87857f3462f7",
   "metadata": {
    "id": "7d06cad8-3c32-48a0-9b98-87857f3462f7"
   },
   "outputs": [],
   "source": [
    "# Tokenize and align labels for whole dataset (We will pad it later)\n",
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"],\n",
    "                                 truncation=True,\n",
    "                                 is_split_into_words=True)\n",
    "    all_labels = examples[\"ner_tags\"]\n",
    "    new_labels = []\n",
    "    for i, labels in enumerate(all_labels):\n",
    "        word_ids = tokenized_inputs.word_ids(i)\n",
    "        new_labels.append(align_labels_with_tokens(labels, word_ids))\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = new_labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9721ab49-3678-4fa3-b754-23afe829ca71",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2e812b97af6a461da555265198d73566",
      "8fc9d5e4e70145919a0d87c23e73e61f",
      "4b4b66cbe55f4f6299a1c00b79042540",
      "db67c6354a094698bd140d2e78e4f32c",
      "ca1ea9e009294085820eb01e4f28bf19",
      "80a0ffff62ff422ea1b80ad793f7c864",
      "83a188eff11444f38304c5571601a487",
      "734ad8720c934e649b2251d645f8bc93",
      "8923e0b8c55842409bcbc5cab0b22f29",
      "312b851e83ca434588ae40440d1d1e77",
      "380e75322a7c413f9ba382d4423e529c"
     ]
    },
    "id": "9721ab49-3678-4fa3-b754-23afe829ca71",
    "outputId": "c6f491c2-bd0c-44b4-afc5-d11d87c3b45b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71d5a875dcc4ff48ab003d4bf15eeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2713df8a3734ebaae1401f75ad5b1cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ab426d42ee49398b05689ddc0c8ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_and_align_labels,\n",
    "    batched=True,\n",
    "    remove_columns=raw_datasets[\"train\"].column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69228b2-c386-4032-8a7f-673525dc0545",
   "metadata": {
    "id": "c69228b2-c386-4032-8a7f-673525dc0545"
   },
   "source": [
    "# Collating data\n",
    "We can't use `DataCollatorWith Padding` because we must now pad both the inputs AND the labels, so we must use `DataCollatorForTokenClassification`, which takes the tokenizer as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38d36462-373f-40bd-b506-0b6a6c9254e9",
   "metadata": {
    "id": "38d36462-373f-40bd-b506-0b6a6c9254e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Trevor_Kinsey\\miniconda3\\envs\\hugging\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer,\n",
    "                                                   return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d090ae-9c53-49d0-81f0-353cad8cab84",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "15d090ae-9c53-49d0-81f0-353cad8cab84",
    "outputId": "ed83ce28-5a89-43e5-b061-4c3146abcf7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-100,    3,    0,    7,    0,    0,    0,    7,    0,    0,    0,\n",
       "        -100],\n",
       "       [-100,    1,    2, -100, -100, -100, -100, -100, -100, -100, -100,\n",
       "        -100]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = data_collator([tokenized_datasets[\"train\"][i] for i in range(2)])\n",
    "batch[\"labels\"].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f10b982d-de48-45bd-87a1-28a3960a3439",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f10b982d-de48-45bd-87a1-28a3960a3439",
    "outputId": "9a8ff24d-d077-43ff-da8f-1ef5ff31d5ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-100, 3, 0, 7, 0, 0, 0, 7, 0, 0, 0, -100]\n",
      "[-100, 1, 2, -100]\n"
     ]
    }
   ],
   "source": [
    "# Compare to just the labels\n",
    "for i in range(2):\n",
    "    print(tokenized_datasets[\"train\"][i][\"labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cadbbb-8203-46d7-9620-774f489c48ed",
   "metadata": {
    "id": "86cadbbb-8203-46d7-9620-774f489c48ed"
   },
   "source": [
    "# Build TF Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aa009653-05b5-4202-8ae8-2c3a8ae7385d",
   "metadata": {
    "id": "aa009653-05b5-4202-8ae8-2c3a8ae7385d"
   },
   "outputs": [],
   "source": [
    "tf_train_dataset = tokenized_datasets[\"train\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=16,\n",
    ")\n",
    "\n",
    "tf_eval_dataset = tokenized_datasets[\"validation\"].to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"labels\", \"token_type_ids\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8cfd26-aac1-42e4-ae23-79972db6b712",
   "metadata": {
    "id": "7e8cfd26-aac1-42e4-ae23-79972db6b712"
   },
   "source": [
    "# The Model\n",
    "The training of the model was done on GPU in google colab and saved to google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p7tll4zZl4Xg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p7tll4zZl4Xg",
    "outputId": "0127d27a-e6ed-44c3-8af3-a5f24ca28241"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/gdrive/MyDrive/repos/huggingface-nlp\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d4baa8-d401-4902-8a73-2b61604c1b3a",
   "metadata": {
    "id": "00d4baa8-d401-4902-8a73-2b61604c1b3a",
    "outputId": "40d39b63-c8c4-4270-ef2e-b468e9ef5915"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Trevor_Kinsey\\miniconda3\\envs\\hugging\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForTokenClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForTokenClassification\n",
    "\n",
    "# translation dictionaries\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = TFAutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c9ad3e-f8f6-4aef-9502-72ef885f5b4d",
   "metadata": {
    "id": "34c9ad3e-f8f6-4aef-9502-72ef885f5b4d"
   },
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "import tensorflow as tf\n",
    "\n",
    "# Train in mixed-precision float16\n",
    "# Comment this line out if you're using a GPU that will not benefit from this\n",
    "tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "# The number of training steps is the number of samples in the dataset, divided by the batch size then multiplied\n",
    "# by the total number of epochs. Note that the tf_train_dataset here is a batched tf.data.Dataset,\n",
    "# not the original Hugging Face Dataset, so its len() is already num_samples // batch_size.\n",
    "num_epochs = 3\n",
    "num_train_steps = len(tf_train_dataset) * num_epochs\n",
    "\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=0,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe61908-2003-4619-ba88-a390a2b9be2b",
   "metadata": {
    "id": "dbe61908-2003-4619-ba88-a390a2b9be2b"
   },
   "source": [
    "Note also that we don’t supply a loss argument to compile(). This is because the models can actually compute loss internally — if you compile without a loss and supply your labels in the input dictionary (as we do in our datasets), then the model will train using that internal loss, which will be appropriate for the task and model type you have chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4a0832-3e02-452e-b405-d281697e799a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e4a0832-3e02-452e-b405-d281697e799a",
    "outputId": "0feb9256-aac9-4926-b40e-34912118802b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-09 02:02:49.216609\n",
      "Epoch 1/3\n",
      "666/878 [=====================>........] - ETA: 43s - loss: 0.0313"
     ]
    }
   ],
   "source": [
    "\n",
    "# from transformers.keras_callbacks import PushToHubCallback\n",
    "\n",
    "# callback = PushToHubCallback(output_dir=\"bert-finetuned-ner\", tokenizer=tokenizer)\n",
    "\n",
    "from datetime import datetime\n",
    "print(datetime.now())\n",
    "\n",
    "model.fit(\n",
    "    tf_train_dataset,\n",
    "    validation_data=tf_eval_dataset,\n",
    "    # callbacks=[callback],\n",
    "    epochs=num_epochs,\n",
    "    verbose=1\n",
    ")\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41799c74-9b72-46f5-9163-7cd0e10faec7",
   "metadata": {
    "id": "41799c74-9b72-46f5-9163-7cd0e10faec7"
   },
   "outputs": [],
   "source": [
    "/content/gdrive/MyDrive/repos/huggingface-nlp"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:hugging]",
   "language": "python",
   "name": "conda-env-hugging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2e812b97af6a461da555265198d73566": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_8fc9d5e4e70145919a0d87c23e73e61f",
       "IPY_MODEL_4b4b66cbe55f4f6299a1c00b79042540",
       "IPY_MODEL_db67c6354a094698bd140d2e78e4f32c"
      ],
      "layout": "IPY_MODEL_ca1ea9e009294085820eb01e4f28bf19"
     }
    },
    "312b851e83ca434588ae40440d1d1e77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "380e75322a7c413f9ba382d4423e529c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4b4b66cbe55f4f6299a1c00b79042540": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_734ad8720c934e649b2251d645f8bc93",
      "max": 3250,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8923e0b8c55842409bcbc5cab0b22f29",
      "value": 3250
     }
    },
    "734ad8720c934e649b2251d645f8bc93": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "80a0ffff62ff422ea1b80ad793f7c864": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "83a188eff11444f38304c5571601a487": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8923e0b8c55842409bcbc5cab0b22f29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8fc9d5e4e70145919a0d87c23e73e61f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_80a0ffff62ff422ea1b80ad793f7c864",
      "placeholder": "​",
      "style": "IPY_MODEL_83a188eff11444f38304c5571601a487",
      "value": "Map: 100%"
     }
    },
    "ca1ea9e009294085820eb01e4f28bf19": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db67c6354a094698bd140d2e78e4f32c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_312b851e83ca434588ae40440d1d1e77",
      "placeholder": "​",
      "style": "IPY_MODEL_380e75322a7c413f9ba382d4423e529c",
      "value": " 3250/3250 [00:00&lt;00:00, 6428.88 examples/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
