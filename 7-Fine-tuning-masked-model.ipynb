{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3615243b-a257-47d8-ae86-b7a4aceb6169",
   "metadata": {},
   "source": [
    "# Fine-tuning masked model\n",
    "If you are using domain-specific language, it is not enough to fine-tune the model head because the underling LLM might classify important tokens as unknown. \n",
    "\n",
    "In these cases you must fine-tune the underlying model (eg. BERT) on your corpus, THEN build/train a task-specific model on top of it. (This process is called *domain adaptation*.\n",
    "\n",
    "Let's do this for a **Masked language model** that can autocomplete sentences, using **DistilBERT** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b940bd7-8596-4809-a39a-b0bf65c40a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1232a9d6967a4e5c9d57d9dfd1f5d0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Trevor_Kinsey\\miniconda3\\envs\\hugging\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "707356314d02459dbcf96b1f7baa125d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Trevor_Kinsey\\miniconda3\\envs\\hugging\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFDistilBertForMaskedLM.\n",
      "\n",
      "All the weights of TFDistilBertForMaskedLM were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForMaskedLM for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TFAutoModelForMaskedLM\n",
    "\n",
    "model_checkpoint = \"distilbert-base-uncased\"\n",
    "model = TFAutoModelForMaskedLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127cfbb1-feac-41a1-b62d-77ee69036dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3db144800ee4098b4c60979af5294dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cbb49abd6694707a4fb7bdcf4732a2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "065d9fdb0cac4e8cb1340700d4aa07cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc61b2c3-0914-4e6a-8d0f-123a37a9bef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try it out on sample text\n",
    "text = \"This is a great [MASK].\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "299afa5c-d7ce-442c-a7c3-99efee0e4008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> This is a great deal.\n",
      ">>> This is a great success.\n",
      ">>> This is a great adventure.\n",
      ">>> This is a great idea.\n",
      ">>> This is a great feat.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"np\")\n",
    "token_logits = model(**inputs).logits\n",
    "\n",
    "# Find the location of [MASK] and extract its logits\n",
    "mask_token_index = np.argwhere(inputs[\"input_ids\"] == tokenizer.mask_token_id)[0, 1]\n",
    "mask_token_logits = token_logits[0, mask_token_index, :]\n",
    "\n",
    "# Pick the [MASK] candidates with the highest logits\n",
    "# We negate the array before argsort to get the largest, not the smallest, logits\n",
    "top_5_tokens = np.argsort(-mask_token_logits)[:5].tolist()\n",
    "\n",
    "for token in top_5_tokens:\n",
    "    print(f\">>> {text.replace(tokenizer.mask_token, tokenizer.decode([token]))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e7603b-4cad-495d-b6cb-3b1ec62be516",
   "metadata": {},
   "source": [
    "# Fine-tuning dataset\n",
    "These are very general terms based on the generic DistilBERT vocabulary. Let's make them more specific to movie reviews but treining on the IMDb [Large Movie Review Datset](https://huggingface.co/datasets/imdb).\n",
    "\n",
    "The dataset has labels `[0,1]` for negative and positive reviews, but we will ignore those and just use the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f2cc71-613b-4aef-a456-cb8e062d30fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdb73f698ec9450bb0ea57fb51fc549f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/7.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b84705055c40b6ae82e6ee70f3ca26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a8d441a7a02477b86c03d6900352e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "866e72fb4431488cb175aab3e58b15d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7620ad1e549e4c578be54fc113617de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d72b0205006343c4ba49f2305752d7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23b2bcbb99824551b41f15f98a1a770f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "imdb_dataset = load_dataset(\"imdb\")\n",
    "imdb_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8281ead-c84b-456a-b822-1e2e5a017c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> Review: There is no relation at all between Fortier and Profiler but the fact that both are police series about violent crimes. Profiler looks crispy, Fortier looks classic. Profiler plots are quite simple. Fortier's plot are far more complicated... Fortier looks more like Prime Suspect, if we have to spot similarities... The main character is weak and weirdo, but have \"clairvoyance\". People like to compare, to judge, to evaluate. How about just enjoying? Funny thing too, people writing Fortier looks American but, on the other hand, arguing they prefer American series (!!!). Maybe it's the language, or the spirit, but I think this series is more English than American. By the way, the actors are really good and funny. The acting is not superficial at all...'\n",
      "'>>> Label: 1'\n",
      "\n",
      "'>>> Review: This movie is a great. The plot is very true to the book which is a classic written by Mark Twain. The movie starts of with a scene where Hank sings a song with a bunch of kids called \"when you stub your toe on the moon\" It reminds me of Sinatra's song High Hopes, it is fun and inspirational. The Music is great throughout and my favorite song is sung by the King, Hank (bing Crosby) and Sir \"Saggy\" Sagamore. OVerall a great family movie or even a great Date movie. This is a movie you can watch over and over again. The princess played by Rhonda Fleming is gorgeous. I love this movie!! If you liked Danny Kaye in the Court Jester then you will definitely like this movie.'\n",
      "'>>> Label: 1'\n",
      "\n",
      "'>>> Review: George P. Cosmatos' \"Rambo: First Blood Part II\" is pure wish-fulfillment. The United States clearly didn't win the war in Vietnam. They caused damage to this country beyond the imaginable and this movie continues the fairy story of the oh-so innocent soldiers. The only bad guys were the leaders of the nation, who made this war happen. The character of Rambo is perfect to notice this. He is extremely patriotic, bemoans that US-Americans didn't appreciate and celebrate the achievements of the single soldier, but has nothing but distrust for leading officers and politicians. Like every film that defends the war (e.g. \"We Were Soldiers\") also this one avoids the need to give a comprehensible reason for the engagement in South Asia. And for that matter also the reason for every single US-American soldier that was there. Instead, Rambo gets to take revenge for the wounds of a whole nation. It would have been better to work on how to deal with the memories, rather than suppressing them. \"Do we get to win this time?\" Yes, you do.'\n",
      "'>>> Label: 0'\n"
     ]
    }
   ],
   "source": [
    "sample = imdb_dataset[\"train\"].shuffle(seed=42).select(range(3))\n",
    "\n",
    "for row in sample:\n",
    "    print(f\"\\n'>>> Review: {row['text']}'\")\n",
    "    print(f\"'>>> Label: {row['label']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefd028c-32d9-4f68-9fbf-305f482de52c",
   "metadata": {},
   "source": [
    "## Preprocesing\n",
    "Some reviews are very short and some are very long, leading to a problem with input size. We don't want to truncate the long ones (losing information) NOR do we want to pad the small ones up to a minimum length (not computationally efficient).\n",
    "\n",
    "The standard approach for a corpus with entries of extremely variable input length is to concatenate all the examples and then split the whole corpus into chunks of equal size. (instead of just tokenizing individual examples). \n",
    "\n",
    "Steps:\n",
    "- tokenize the corpus ***without*** setting `truncation=True`, and getting the word_ids\n",
    "- remove the `text` and `label` columns (no longer needed)\n",
    "- group together all examples\n",
    "- break into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dff022-43ad-47e1-b1fd-b0ba03c3c984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77b9f3e5-93ea-4766-9eb4-d896166cc7ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1620b1c2f0e4505838ea0a6f73cbbe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (720 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb88828f44b449c286896d481e9df213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7066fcaba8564d0281b559b0a6ef1492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    result = tokenizer(examples[\"text\"])\n",
    "    if tokenizer.is_fast:\n",
    "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
    "    return result\n",
    "\n",
    "# Use batched=True to activate fast multithreading!\n",
    "tokenized_datasets = imdb_dataset.map(\n",
    "    tokenize_function, batched=True, remove_columns=[\"text\", \"label\"]\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a82e351-86ce-4d05-86e5-f7cba3be7850",
   "metadata": {},
   "source": [
    "### Chunking the data\n",
    "To determine the chunk size we need to know the model's maximum input size. For DistillBERT it is `512`, though other models have longer ones.\n",
    "To make this work in a google colab environment, set to smaller, like `128` (BUT BIGGER IS REALLY BETTER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9a65b82-7088-4752-9962-a4be201beb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model max input length = 512\n",
      "we will use chunk_size = 128\n"
     ]
    }
   ],
   "source": [
    "chunk_size = 128\n",
    "\n",
    "print(f\"model max input length = {tokenizer.model_max_length}\")\n",
    "print(f\"we will use chunk_size = {chunk_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2e286c34-2a78-45ea-98bc-d3b6510f8161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'>>> Review 0 length: 363'\n",
      "'>>> Review 1 length: 304'\n",
      "'>>> Review 2 length: 133'\n"
     ]
    }
   ],
   "source": [
    "# See how many tokens in each review\n",
    "tokenized_samples = tokenized_datasets[\"train\"][:3]\n",
    "\n",
    "for idx, sample in enumerate(tokenized_samples[\"input_ids\"]):\n",
    "    print(f\"'>>> Review {idx} length: {len(sample)}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae028fab-e6e8-4a7c-a588-987f5a251a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Concatenated reviews length: 800'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 128'\n",
      "'>>> Chunk length: 32'\n"
     ]
    }
   ],
   "source": [
    "# concatenate them together\n",
    "concatenated_examples = {k: sum(tokenized_samples[k], []) for k in tokenized_samples.keys()}\n",
    "total_length = len(concatenated_examples[\"input_ids\"])\n",
    "print(f\"'Concatenated reviews length: {total_length}'\")\n",
    "\n",
    "# break into chunks\n",
    "chunks = {\n",
    "    k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "    for k, t in concatenated_examples.items()\n",
    "}\n",
    "\n",
    "for chunk in chunks[\"input_ids\"]:\n",
    "    print(f\"'>>> Chunk length: {len(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ad9d58-fcea-4a93-ae72-c5fdfa0eb15b",
   "metadata": {},
   "source": [
    "We can either pad the last chunk up to `chunk_size`, or we can just drop it. Let's drop it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4984ec7f-f8d4-4639-afaf-55ecd8e84d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_texts(examples):\n",
    "    # Concatenate all texts\n",
    "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
    "    \n",
    "    # Compute length of concatenated texts\n",
    "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
    "    \n",
    "    # Drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = (total_length // chunk_size) * chunk_size\n",
    "    # Split by chunks of max_len\n",
    "    result = {\n",
    "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
    "        for k, t in concatenated_examples.items()\n",
    "    }\n",
    "    # Create a new labels column that contains the ground truth for the prediction task\n",
    "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c022f797-0536-414b-8b87-5ef867f19a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5191328e8e3a491f896b3386eb6ed2bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0feba3fee9444868eeb52a2c0d9289a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3444dfeeae1e44b88e6fd339acdfb093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 61291\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 59904\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 122957\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
    "lm_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "563ecbef-f89c-4af6-bf8d-a642d3bdf59b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"as the vietnam war and race issues in the united states. in between asking politicians and ordinary denizens of stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men. < br / > < br / > what kills me about i am curious - yellow is that 40 years ago, this was considered pornographic. really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. while my countrymen mind find it shocking, in reality sex and nudity are a major staple in swedish cinema. even ingmar bergman,\""
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine example\n",
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c6830c-69d1-4db8-a786-648aabafb02b",
   "metadata": {},
   "source": [
    " Note that 2 different reviews are separated by the `[SEP] [CLS]` tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0855fc88-c536-45ad-b4c9-77035963e75f",
   "metadata": {},
   "source": [
    "## DataCollator: insert random `[MASK]` tokens so that our model can learn.\n",
    "Up to this point the model has identical inputs and labels. We need to add `[MASK]` tokens to the inputs ontherwise inputs=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c01934e1-034e-4b93-9d5b-18d6388842d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(lm_datasets[\"train\"][1][\"input_ids\"]) == tokenizer.decode(lm_datasets[\"train\"][1][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c1c30851-a389-427e-9cc6-1e1c06ad8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm_probability = 0.15 # fraction of tokens to mask\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "26d85484-a01c-4644-ad36-9bd1ff4c8cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'>>> [CLS] i rented i am [MASK] - yellow from my video store because of all the controversy that surrounded [MASK] when it was first released in 1967. i also heard that at first [MASK] was seized by u. s. customs if it ever tried to [MASK] this country, therefore being a fan [MASK] films considered \" controversial [MASK] i really [MASK] [MASK] see this migrated [MASK]. < br / > < br / jeanne the plot is centered around a young swedish drama student [MASK] lena who wants to learn everything she can about [MASK]. in particular she wants to focus her attentions [MASK] making some sort of documentary on what the average swede [MASK] about [MASK] political issues such'\n",
      "\n",
      "'>>> as the vietnam war [MASK] race issues in the [MASK] states [MASK] in between asking politicians and [MASK] denizens of stockholm about their opinions on politics, she has sex with her drama teacher, classmates [MASK] [MASK] married [MASK] [MASK] < br / > < br / > what kills me about i am mud - yellow is that 40 years ago [MASK] this was [MASK] pornographic [MASK] really [MASK] the pressured and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. while [MASK] countrymen mind find [MASK] shocking, in reality sex [MASK] nudity are a major staple in swedish methane. even ingmar bergman,'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "for sample in samples:\n",
    "    _ = sample.pop(\"word_ids\")\n",
    "\n",
    "for chunk in data_collator(samples)[\"input_ids\"]:\n",
    "    print(f\"\\n'>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8af66f2-c43a-46b7-a70e-e85f27ebeacc",
   "metadata": {},
   "source": [
    "**Problem:** This collator will mask individual tokens, which may or may not make up an entire word. We want to us **whole-word-masking**, so we can make our own DataCollator, which is just a function that takes a list of samples and converts them into a batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01eeb6dd-24e8-4c9a-9fc9-b6489961aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "from transformers.data.data_collator import tf_default_data_collator\n",
    "\n",
    "wwm_probability = 0.2 # probability that a whole word is masked\n",
    "\n",
    "\n",
    "def whole_word_masking_data_collator(datasets):\n",
    "    for dataset in datasets:\n",
    "        word_ids = dataset.pop(\"word_ids\")\n",
    "\n",
    "        # Create a map between words and corresponding token indices\n",
    "        mapping = collections.defaultdict(list)\n",
    "        current_word_index = -1\n",
    "        current_word = None\n",
    "        for idx, word_id in enumerate(word_ids):\n",
    "            if word_id is not None:\n",
    "                if word_id != current_word:\n",
    "                    current_word = word_id\n",
    "                    current_word_index += 1\n",
    "                mapping[current_word_index].append(idx)\n",
    "\n",
    "        # Randomly mask words\n",
    "        mask = np.random.binomial(1, wwm_probability, (len(mapping),))\n",
    "        input_ids = dataset[\"input_ids\"]\n",
    "        labels = dataset[\"labels\"]\n",
    "        new_labels = [-100] * len(labels)\n",
    "        for word_id in np.where(mask)[0]:\n",
    "            word_id = word_id.item()\n",
    "            for idx in mapping[word_id]:\n",
    "                new_labels[idx] = labels[idx]\n",
    "                input_ids[idx] = tokenizer.mask_token_id\n",
    "        dataset[\"labels\"] = new_labels\n",
    "\n",
    "    return tf_default_data_collator(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b5a6546f-6304-4078-ae71-015c244d2c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> [CLS] i rented i am curious [MASK] [MASK] from my video store because of all the controversy that surrounded it when it was first released in 1967. i also heard that at [MASK] [MASK] was seized by u [MASK] s. customs if [MASK] ever [MASK] to [MASK] this country [MASK] therefore being a fan of films considered \" [MASK] [MASK] i really had to see this for myself. < br [MASK] > < [MASK] [MASK] > the plot is centered around a young swedish drama student [MASK] lena [MASK] wants [MASK] learn everything she can about life. in particular she wants [MASK] focus her attentions to making some sort of documentary on what [MASK] average swede thought about certain [MASK] issues such'\n",
      "\n",
      ">>> as [MASK] vietnam war and race issues in [MASK] united states [MASK] in between asking politicians and ordinary denizens of [MASK] about their opinions on [MASK], she has [MASK] with [MASK] drama teacher, classmates [MASK] and married men [MASK] < [MASK] / [MASK] < [MASK] [MASK] > what kills me [MASK] i am curious [MASK] yellow is that 40 years ago, this [MASK] [MASK] pornographic. [MASK], the [MASK] and nudity [MASK] are [MASK] and far between, even then it's [MASK] shot like some cheaply made porno. while my countrymen mind find it shocking, in [MASK] sex and nudity are a major [MASK] in swedish cinema. [MASK] [MASK] [MASK] bergman,'\n"
     ]
    }
   ],
   "source": [
    "samples = [lm_datasets[\"train\"][i] for i in range(2)]\n",
    "batch = whole_word_masking_data_collator(samples)\n",
    "\n",
    "for i, chunk in enumerate(batch[\"input_ids\"]):\n",
    "    print(f\"\\n>>> {tokenizer.decode(chunk)}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82228f2-8c10-4e65-afbc-0ea03f00427b",
   "metadata": {},
   "source": [
    "# Training\n",
    "We will downsample the training set to reduce training time (optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3ef46dfa-db1f-42ea-846d-c26915dfddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'distilbert-base-uncased'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "df6ac83a-3c08-4117-9471-9a0b83c2568a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Roverto/distilbert-base-uncased-finetuned-imdb'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_user = \"Roverto\"\n",
    "model_name = f\"{model_checkpoint}-finetuned-imdb\"\n",
    "hf_repo = f\"{hf_user}/{model_name}\"\n",
    "hf_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d37db58d-59f7-4ff3-a47d-5d5186b7414f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'word_ids', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = 10_000\n",
    "test_size = int(0.1 * train_size)\n",
    "\n",
    "downsampled_dataset = lm_datasets[\"train\"].train_test_split(\n",
    "    train_size=train_size, test_size=test_size, seed=42\n",
    ")\n",
    "downsampled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d153a0fc-6597-4236-abe3-6033ceaeb26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434fe167c0da45c68b005806653a7414",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "393c04e0-3d07-4a12-99c7-4c9338ce16fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_train_dataset = model.prepare_tf_dataset(\n",
    "    downsampled_dataset[\"train\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=True,\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "tf_eval_dataset = model.prepare_tf_dataset(\n",
    "    downsampled_dataset[\"test\"],\n",
    "    collate_fn=data_collator,\n",
    "    shuffle=False,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "495ffe4d-c5f6-4ae3-b646-e823d0ce34cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import create_optimizer\n",
    "from transformers.keras_callbacks import PushToHubCallback\n",
    "import tensorflow as tf\n",
    "\n",
    "num_train_steps = len(tf_train_dataset)\n",
    "optimizer, schedule = create_optimizer(\n",
    "    init_lr=2e-5,\n",
    "    num_warmup_steps=1_000,\n",
    "    num_train_steps=num_train_steps,\n",
    "    weight_decay_rate=0.01,\n",
    ")\n",
    "model.compile(optimizer=optimizer)\n",
    "\n",
    "# # Train in mixed-precision float16\n",
    "# tf.keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "\n",
    "\n",
    "# callback = PushToHubCallback(\n",
    "#     output_dir=hf_repo, tokenizer=tokenizer\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c3207f35-23bd-4f20-9864-ff952471bead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Trevor_Kinsey\\miniconda3\\envs\\hugging\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "32/32 [==============================] - 97s 3s/step - loss: 3.1566\n",
      "Perplexity: 23.49\n"
     ]
    }
   ],
   "source": [
    "# Check perplexity of model before retraining\n",
    "import math\n",
    "\n",
    "eval_loss = model.evaluate(tf_eval_dataset)\n",
    "print(f\"Perplexity: {math.exp(eval_loss):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582e6f5-1512-418a-9445-ff673f46f17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7/312 [..............................] - ETA: 44:30 - loss: 3.2779"
     ]
    }
   ],
   "source": [
    "model.fit(tf_train_dataset, validation_data=tf_eval_dataset, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca8e09f-d74b-412c-a7d7-ed4a6d38d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the model\n",
    "from transformers import pipeline\n",
    "\n",
    "mask_filler = pipeline(\n",
    "    \"fill-mask\", \n",
    "    model=\"huggingface-course/distilbert-base-uncased-finetuned-imdb\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:hugging]",
   "language": "python",
   "name": "conda-env-hugging-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
